<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data manipulation | Kyle Zimmerschied</title>
    <link>https://mikenguyen.netlify.app/tag/data-manipulation/</link>
      <atom:link href="https://mikenguyen.netlify.app/tag/data-manipulation/index.xml" rel="self" type="application/rss+xml" />
    <description>data manipulation</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Kyle Zimmerschied 2023</copyright><lastBuildDate>Sat, 20 Feb 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://mikenguyen.netlify.app/media/social_sharing_image.png</url>
      <title>data manipulation</title>
      <link>https://mikenguyen.netlify.app/tag/data-manipulation/</link>
    </image>
    
    <item>
      <title>fix for &#34;cannot allocate vector of size&#34;</title>
      <link>https://mikenguyen.netlify.app/post/fix-for-cannot-allocate-vector-of-size/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/fix-for-cannot-allocate-vector-of-size/</guid>
      <description>
&lt;script src=&#34;https://mikenguyen.netlify.app/post/fix-for-cannot-allocate-vector-of-size/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;More package author’s introduction, please access this &lt;a href=&#34;https://cran.r-project.org/web/packages/disk.frame/readme/README.html&#34;&gt;link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instead of loading everything at once into your RAM, you divide your data into chunks.
To quote author of the &lt;code&gt;disk.frame&lt;/code&gt; package: “we go from”R can only deal with data that fits in RAM&#34; to “R can deal with any data that fits on disk”.&#34; While &lt;code&gt;data.frame&lt;/code&gt; uses in-RAM to process, &lt;code&gt;disk.frame&lt;/code&gt; uses hard drive to store and process data.&lt;code&gt;disk.frame&lt;/code&gt; also allows parallel processing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;disk.frame&amp;quot;) 
# setup_disk.frame() # sets up background workers equal to the number of CPU c res setup_disk.frame(workers =\ 2) \# or you number of workers options(future.globals.maxSize = \Inf) # large dataset can be transferred between sessions
# attr(data.df, &amp;quot;path&amp;quot;) # path to where the disk.frame is 


# to convert data.frame to a     disk.frame
data.df &amp;lt;- as.disk.frame(original_data_frame)

# to convert one large CSV
# takes care of splitting large CSV into smaller ones 
diskf &amp;lt;- disk.frame::csv_to_disk.frame(path_to_csv_file) # you can also specify,outdir = , overwrite = T.     

# to convert multiple CSV
multiple_CSV = c(path_to_csv_file1,path_to_csv_file2)
diskf = disk.frame::csv_to_disk.frame(multiple_CSV)

# for faster performance, specify which column to manipulate
result  = df %&amp;gt;% 
  srep(c(&amp;quot;column1&amp;quot;,&amp;quot;column2&amp;quot;)) %&amp;gt;%
  dplyr::filter()&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Connect WRDS in R</title>
      <link>https://mikenguyen.netlify.app/post/connect-wrds-in-r/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/connect-wrds-in-r/</guid>
      <description>
&lt;link href=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Connect from R to Wharton Research Data Services&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# to set up connection from R to WRDS (https://wrds-www.wharton.upenn.edu/pages/support/programming-wrds/programming-r/r-from-your-computer/)
library(RPostgres)
library(dplyr)

# I&amp;#39;ve set up wrds connection before hand. Please use your username and password here.

# wrds &amp;lt;- dbConnect(Postgres(),
#                   host=&amp;#39;wrds-pgdata.wharton.upenn.edu&amp;#39;,
#                   port=9737,
#                   dbname=&amp;#39;wrds&amp;#39;,
#                   sslmode=&amp;#39;require&amp;#39;,
#                   user=&amp;#39;&amp;#39;)

# Check variables (column headers) in COMP ANNUAL FUNDAMENTAL
#uses the already-established wrds connection to prepare the SQL query string and save the query as the result res.
# check avaiable databases: https://wrds-web.wharton.upenn.edu/wrds/tools/variable.cfm?vendor_id=7
res &amp;lt;- dbSendQuery(wrds, &amp;quot;select column_name
                   from information_schema.columns
                   where table_schema=&amp;#39;compa&amp;#39;
                   and table_name=&amp;#39;funda&amp;#39;
                   order by column_name&amp;quot;)
data &amp;lt;- dbFetch(res, n=-1) # fetches the data that results from running the query res against wrds and stores it as data
dbClearResult(res) # closes the connection
head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   column_name
## 1       acchg
## 2        acco
## 3       accrt
## 4     acctchg
## 5     acctstd
## 6        acdo&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# select everything
res &amp;lt;- dbSendQuery(wrds, &amp;quot;select * from compa.funda&amp;quot;)

# from compa.funda

# only select the following variables
res &amp;lt;- dbSendQuery(wrds, &amp;quot;select gvkey, datadate, fyear, indfmt, consol, popsrc, datafmt, tic, cusip, conm, curcd, fyr, act, at, bkvlps, ceq, ch, che, dltt, dlc, emp, np, exchg, cik, costat, naicsh,mkvalt from compa.funda&amp;quot;) #check variables from (https://wrds-web.wharton.upenn.edu/wrds/ds/comp/funda/index.cfm?navId=80)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in result_create(conn@ptr, statement): Closing open result set,
## cancelling previous query&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- dbFetch(res, n=-1)
dbClearResult(res)

head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    gvkey   datadate fyear indfmt consol popsrc datafmt  tic     cusip
## 1 001000 1961-12-31  1961   INDL      C      D     STD AE.2 000032102
## 2 001000 1962-12-31  1962   INDL      C      D     STD AE.2 000032102
## 3 001000 1963-12-31  1963   INDL      C      D     STD AE.2 000032102
## 4 001000 1964-12-31  1964   INDL      C      D     STD AE.2 000032102
## 5 001000 1965-12-31  1965   INDL      C      D     STD AE.2 000032102
## 6 001000 1966-12-31  1966   INDL      C      D     STD AE.2 000032102
##                    conm curcd fyr   act    at bkvlps   ceq ch   che  dltt   dlc
## 1 A &amp;amp; E PLASTIK PAK INC   USD  12    NA    NA 2.4342    NA NA    NA 0.100    NA
## 2 A &amp;amp; E PLASTIK PAK INC   USD  12    NA    NA 3.0497 0.552 NA    NA 0.000    NA
## 3 A &amp;amp; E PLASTIK PAK INC   USD  12 0.408    NA 2.9731 0.553 NA    NA 0.015    NA
## 4 A &amp;amp; E PLASTIK PAK INC   USD  12 0.718 1.416 3.0969 0.607 NA 0.269 0.522 0.088
## 5 A &amp;amp; E PLASTIK PAK INC   USD  12 0.725 2.310 2.3835 0.491 NA 0.031 1.154 0.300
## 6 A &amp;amp; E PLASTIK PAK INC   USD  12 1.015 2.430 3.8082 0.834 NA 0.063 1.109 0.124
##   emp    np exchg  cik costat naicsh mkvalt
## 1  NA    NA    12 &amp;lt;NA&amp;gt;      I     NA     NA
## 2  NA    NA    12 &amp;lt;NA&amp;gt;      I     NA     NA
## 3  NA    NA    12 &amp;lt;NA&amp;gt;      I     NA     NA
## 4  NA 0.000    12 &amp;lt;NA&amp;gt;      I     NA     NA
## 5  NA 0.225    12 &amp;lt;NA&amp;gt;      I     NA     NA
## 6  NA 0.050    12 &amp;lt;NA&amp;gt;      I     NA     NA&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Linking Financial Databases (CRSP and Compustat)</title>
      <link>https://mikenguyen.netlify.app/post/link_crsp_compustat/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/link_crsp_compustat/</guid>
      <description>
&lt;link href=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Information can be found in &lt;a href=&#34;https://www.otago.ac.nz/library/pdf/CRSPCompustatguide09.pdf&#34;&gt;CRSP/COMPUSTAT MERGED DATABASE GUIDE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Change Identifiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ticker&lt;/strong&gt;: can be reassign to another company - abbreviation used to uniquely identify publicly-traded shares of a stock&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUSIP&lt;/strong&gt;: A company can have multiple CUSIPS due to structural changes. - nine-character code assigned by the CUSIP Service Bureau to identify various securities&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Permanent Identifiers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CRSP (maintained by Chicago BOoth CRSP)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PERMCO&lt;/strong&gt;: is a unique permanent company level identifier (even under name change)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PERMNO&lt;/strong&gt;: is a unique stock (share class) level identifier. One company can have multiple share classes. (1 PERMNO -&amp;gt; 1 PERMCO, 1 -&amp;gt; multiple PERMNOs)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Compustat-Capital IQ (maintained by S&amp;amp;P)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GVKEY&lt;/strong&gt;: is a unique number assigned to each company.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;CRSP&lt;/th&gt;
&lt;th&gt;COMPUSTAT&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Time since&lt;/td&gt;
&lt;td&gt;1925&lt;/td&gt;
&lt;td&gt;1950&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Companies&lt;/td&gt;
&lt;td&gt;listed in U.S. Exchange&lt;/td&gt;
&lt;td&gt;U.S. + Canada&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Report&lt;/td&gt;
&lt;td&gt;Daily and Monthly&lt;/td&gt;
&lt;td&gt;Quarterly and Annually&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Apache Arrow</title>
      <link>https://mikenguyen.netlify.app/post/apache-arrow/</link>
      <pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/apache-arrow/</guid>
      <description>
&lt;link href=&#34;index_files/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;index_files/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;more information can be found in &lt;a href=&#34;https://ursalabs.org/&#34;&gt;URSA Labs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This example is from &lt;a href=&#34;https://ursalabs.org/arrow-r-nightly/articles/dataset.html&#34;&gt;Arrow Vignettes&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;arrow&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;arrow&lt;/h1&gt;
&lt;p&gt;best when working with big data&lt;/p&gt;
&lt;div id=&#34;prep&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prep&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;arrow&amp;quot;, warn.conflicts = FALSE)
library(&amp;quot;dplyr&amp;quot;, warn.conflicts = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;check if S3 support is included.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrow::arrow_with_s3()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If TRUE, sync data locally import from &lt;a href=&#34;https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page&#34;&gt;https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrow::copy_files(&amp;quot;s3://ursa-labs-taxi-data&amp;quot;, &amp;quot;nyc-taxi&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;since the data is in Parquet format, we use&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ds &amp;lt;- open_dataset(&amp;quot;nyc-taxi&amp;quot;, partitioning = c(&amp;quot;year&amp;quot;, &amp;quot;month&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then you can start using data set as usual&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ds&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
