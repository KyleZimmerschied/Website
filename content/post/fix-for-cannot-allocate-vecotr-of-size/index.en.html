---
title: fix for "cannot allocate vecotr of size"
author: ''
date: '2021-02-20'
slug: fix-for-cannot-allocate-vecotr-of-size
categories:
  - R
tags:
  - data
  - data manipulation
  - R
subtitle: ''
summary: ''
authors: []
lastmod: '2021-02-20T12:48:28-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<p>More package author’s introduction, please access this <a href="https://cran.r-project.org/web/packages/disk.frame/readme/README.html">link</a></p>
<p>Instead of loading everything at once into your RAM, you divide your data into chunks. To quote author of the <code>disk.frame</code> package: “we go from”R can only deal with data that fits in RAM" to “R can deal with any data that fits on disk”." While <code>data.frame</code> uses in-RAM to process, <code>disk.frame</code> uses hard drive to store and process data.</p>
<p><code>disk.frame</code> also allows parallel processing.</p>
<pre class="r"><code>library(&quot;disk.frame&quot;)
# setup_disk.frame() # sets up background workers equal to the number of CPU cores
setup_disk.frame(workers = 2) # or you number of workers
options(future.globals.maxSize = Inf) # large dataset can be transferred between sessions  
# attr(data.df, &quot;path&quot;) # path to where the disk.frame is stored</code></pre>
<pre class="r"><code># to convert data.frame to a disk.frame
data.df &lt;- as.disk.frame(original_data_frame)

# to convert one large CSV
# takes care of splitting large CSV into smaller ones 
diskf &lt;- disk.frame::csv_to_disk.frame(path_to_csv_file) # you can also specify, outdir = , overwrite = T. 

# to convert multiple CSV
multiple_CSV = c(path_to_csv_file1,path_to_csv_file2)
diskf = disk.frame::csv_to_disk.frame(multiple_CSV)

# for faster performance, specify which column to manipulate
result = df %?% 
  srckeep(c(&quot;column1&quot;,&quot;column2&quot;)) %&gt;%
  dplyr::filter()</code></pre>
